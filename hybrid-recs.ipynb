{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Subsystems and Supersystems\n",
    "\n",
    "#### Go read this\n",
    "\n",
    "This winter school explores the structure of recommender systems using the hybridisation taxonomy introduced by R. Burke in\n",
    "- \"Hybrid Recommender Systems: Survey and Experiments\", 2002, article in \"User Modeling and User-Adapted Interaction\"\n",
    "- \"Hybrid Web Recommender Systems\", 2007, book chapter in \"The Adaptive Web\"\n",
    "\n",
    "which is still used in literatures reviews as recently as E. Cano, M. Morisio (Jan 2019) and Wikipedia (Jan 2020).\n",
    "\n",
    "It also borrows heavily from the chapter on recommendations in Ilya Katsov's \"Introduction to Algorithmic Marketing\" (2018).\n",
    "\n",
    "\n",
    "#### Turtles all the way down\n",
    "\n",
    "Recommender Hybridisation typically embeds recommender systems into larger recommender systems.\n",
    "\n",
    "A _holon_ is a whole system that is also part of a larger system. A holon is distinct from the other systems that are also part of the larger system. A _holarchy_ is a hierarchy of holons; holarchies clarify the levels of embeddedness at which individual systems operate, the subsystems they are composed of, and the supersystems they are parts of.\n",
    "\n",
    "Recommender Systems are starting to become complicated enough that they exhibit holarchic structure: They\n",
    "- are \"wholes\" made up of multiple systems \n",
    "    - existing at multiple levels of embeddedness\n",
    "    - interacting with one another within these levels\n",
    "- can exist as \"parts\" within larger (hybrid) recommender systems\n",
    "\n",
    "This winter school explores these \"whole\" and \"part\" aspects of Recs systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a Recommender System (\"Whole\" aspect)\n",
    "\n",
    "Recs Systems can be conceived of as having three sequential \"subsystems\":\n",
    "\n",
    "1. candidate generation: This subsystem (typically a ML model) shortlists candidates to rank/recommend\n",
    "2. ranking / scoring: This subsystem (typically a sorting system) ranks/scores these candidates\n",
    "3. re-ranking / re-scoring: A final model (typically a rules-based system) re-ranks/re-scores these candidates\n",
    "\n",
    "In the Holarchic structure, these three sequential subsystems exist at the same level of embeddedness and interact with one another (e.g. the candidates generated by the first subsystem feed into the second subsystem). Each of these systems can contain further subsystems (e.g. candidate generation can be a hybrid of two recommenders).\n",
    "\n",
    "Burke does not explicitly consider subsystems of a recs system as such, instead considering the time-ordered _phases_ of a recs system,\n",
    "\n",
    "1. training\n",
    "2. candidate generation\n",
    "3. scoring\n",
    "\n",
    "Burke's diagrams accompanying this phase-based view clearly show how recommenders are embedded into the candidate generation and scoring components of hybrid recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Generation Subsystem\n",
    "\n",
    "Typical examples include Collaborative Filtering, Content Filtering, and (less commonly) Knowledge-based Filtering. These candidate generation systems have complementary 'PRO's and 'CON's (which is why hybridising them works in the first place)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "Given ratings of many products by many users, and given a set of users \"similar\" to a given user, a \"rating from similar users\" can be _aggregated_ for each product, and a set of candidates determined from this aggregate rating from similar users. This is a \"user-item\" Collaborative Filtering algorithm. There are also item-item CF algorithms, which work somewhat similarly.\n",
    "\n",
    "PROS:\n",
    "- promotes new behaviors in the user (discovery)\n",
    "- bla\n",
    "\n",
    "CONS:\n",
    "- must have ratings of many products by many users (cold start)\n",
    "- bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Filtering\n",
    "\n",
    "Given features of products, and given a user's ratings of other products, a _binary classifer_ that fits the user's rating behavior can be generated, and used to determine a set of candidates.\n",
    "\n",
    "PROS:\n",
    "- bla\n",
    "- bla\n",
    "\n",
    "CONS:\n",
    "- must have a user's ratings history (cold start)\n",
    "- only promotes user's observed behavior (no discovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\n",
    "# scikit-learn a simple classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge-based Filtering\n",
    "\n",
    "Given explicit knowledge of a user's needs and preferences, and explicit knowledge of how certain products or product features meet these needs, a set of candidates can be _logically inferred_ (via logic programming or otherwise).\n",
    "\n",
    "PROS:\n",
    "- no cold start\n",
    "- human-interpetable inference rules\n",
    "\n",
    "CONS:\n",
    "- new inference rules (knowledge) are usually hand-crafted\n",
    "- only promotes behavior we already know about (no discovery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problog.program import PrologString\n",
    "from problog import get_evaluatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"\"\"\n",
    "% Explicit knowledge about which products satisfy which needs\n",
    "\n",
    "% Rule: if user has a given need, then this product should be candidate\n",
    "trousers_923657(X) :- needs_trousers(X).\n",
    "trousers_984520(X) :- needs_trousers(X).\n",
    "dress_83745(X) :- needs_dress(X).\n",
    "\n",
    "% Manual Rule: People who never shop in female categories don't want dresses\n",
    "\n",
    "needs_trousers(X) :- shops_female(X).\n",
    "needs_dress(X) :- shops_female(X).\n",
    "needs_trousers(X) :- not(shops_female(X)).\n",
    "% needs_dress(X) :- not(shops_female(X)).  <-- not recommended!\n",
    "\n",
    "\n",
    "% Manual Rule: get rid of excess stcok of ugly trousers by\n",
    "% recommending them to people who have poor taste in clothes\n",
    "\n",
    "ugly_trousers(X) :- needs_trousers(X), not(shops_female(X)).\n",
    "\"\"\"\n",
    "\n",
    "queries = \"\"\"\n",
    "shops_female(1).\n",
    "not(shops_female(2)).\n",
    "\n",
    "query(trousers_923657(1)).\n",
    "query(trousers_984520(1)).\n",
    "query(ugly_trousers(1)).\n",
    "query(dress_83745(1)).\n",
    "\n",
    "query(trousers_923657(2)).\n",
    "query(trousers_984520(2)).\n",
    "query(ugly_trousers(2)).\n",
    "query(dress_83745(2)).\n",
    "\"\"\"\n",
    "\n",
    "problog_string = model+queries\n",
    "\n",
    "result = get_evaluatable().create_from(PrologString(problog_string)).evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{trousers_923657(1): 1.0,\n",
       " trousers_984520(1): 1.0,\n",
       " ugly_trousers(1): 0.0,\n",
       " dress_83745(1): 1.0,\n",
       " trousers_923657(2): 1.0,\n",
       " trousers_984520(2): 1.0,\n",
       " ugly_trousers(2): 1.0,\n",
       " dress_83745(2): 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking / Scoring Subsystem\n",
    "\n",
    "Recommendation systems typically sort their candidates into an ordered list.\n",
    "\n",
    "Given a scoring function $f({\\rm candidate}) \\to {\\rm score}$, this system performs two operations\n",
    "- Computes the scores `scores = map(f, candidate_shortlist)`\n",
    "- Ranks the candidates by their scores `sort(by=score, zip(scores, candidate_shortlist))`\n",
    "\n",
    "The choice of a scoring function $f$ need not be informed by the scores used by the candidate generator subsystem. The scoring function $f$ may depend on an individual user's context.\n",
    "\n",
    "### Scoring\n",
    "\n",
    "TODO\n",
    "\n",
    "### Sorting\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranking/Re-scoring Subsystem\n",
    "\n",
    "The point of a re-scoring/re-ranking subsystem is that the scoring/ranking subsystem considers candidates _individually_ while the second pass allows us to fine tune the candidates as a _group_. We might care about visitor-centric properties of the recommendations (e.g. Promotions / Blacklists / Whitelists / Price Anchoring) or about \"digital storefront\" concerns (e.g. coordination of multiple carousels, manual curation, carousel slot takeovers) or even about ML concerns (e.g. exploration of 'new' candidates for recs, explicit unbiasing, ...)\n",
    "\n",
    "### Rules\n",
    "\n",
    "Rules-based subsystems in Recs can be described by a BDD-style description:\n",
    "    ```\n",
    "    GIVEN <CONTEXT> [AND <CONTEXT> ...]*,\n",
    "    WHEN <TRIGGER>,\n",
    "    THEN <BEHAVIOR>.\n",
    "    ```\n",
    "e.g.\n",
    "    - `GIVEN user.category_preference=socks, WHEN (...) THEN (PROMOTE category=shoes)`\n",
    "    - `GIVEN seed.price AS minimum, WHEN (...), THEN (BLACKLIST price < minimum)`  -- \"don't downsell\"\n",
    "    - `GIVEN seed.category=X, WHEN (...), THEN (CURATE category=Y)`  -- \"complete the look\"\n",
    "\n",
    "The explicit distinction between context and trigger means that we can trigger rule-checks at different times, to create a prioritised sequence of rules (which enables us to use rules that \"do not commute\").\n",
    "\n",
    "Unlike Re-ranking/Re-scoring systems, candidate generation systems (above) do not need to supply a scoring/ranking of their candidates. The output of a (Knowledge-based Filtering)  candidate generation system  needs to be ranked and sorted by the Ranking / Scoring subsystem; the output of a re-ranking/re-scoring system is already ranked and sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybridising Recommender Systems (\"Part aspect\")\n",
    "\n",
    "Burke distinguishes seven ways of hybridising Recs systems:\n",
    "\n",
    "1. Weighted: The score of different recommendation components are combined numerically.\n",
    "2. Switching: The system chooses among recommendation components and applies the selected one.\n",
    "3. Mixed: Recommendations from different recommenders are presented together.\n",
    "4. Feature Combination: Features derived from different knowledge sources are combined together and given to a single recommendation algorithm.\n",
    "5. Feature Augmentation: One recommendation technique is used to compute a feature or set of features, which is then part of the input to the next technique.\n",
    "6. Cascade: Recommenders are given strict priority, with the lower priority ones breaking ties in the scoring of the higher ones.\n",
    "7. Meta-level: One recommendation technique is applied and produces some sort of model, which is then the input used by the next technique.\n",
    "\n",
    "We will discuss each hybridisation in more detail below.\n",
    "\n",
    "Katsov distinguishes _blending_ hybridisations, which perform _ensemble learning_ over recommenders, from the simpler hybridisations (Switching, Mixing). The important insight here is that _hybridisation is ensemble learning_. We will find all of the usual techniques: bootstrap aggregating == ???, gating == switching, ...\n",
    "\n",
    "As in any taxonomy, the taxons are arbitrary conceptual distinctions. Recommender systems did not evolve in order to manifest a taxonomy, the taxonomy was created to classify recommender system hybrids. By analogy with biology, recall that cultural evolution is the driving force behind the emergence of new species of Recs systems. In the biosphere, hybridisation (an explicit blurring of species distinctions) is feature of polyploidy. Burke's taxonomy _of hybridisation_ would consider genetic hybrids as \"Mixing\" hybrids (each parent 'recommends' one set of chromosomes, which are presented together in the genotype).\n",
    "\n",
    "This taxonomy does not account for the existence of subsystems of recommendation systems: Does hybridisation occur\n",
    "- inside the candidate generation system?\n",
    "- between candidate generation and scoring?\n",
    "- inside the scoring system?\n",
    "- between scoring and re-scoring?\n",
    "- inside re-scoring system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights (aka Stacking)\n",
    "\n",
    "In ensemble learning, this form of hybridisation is known as stacking (which is how we will refer to this hybridisation from now on). Given scores $s_{ri}$ for multiple items (indexed by $i$) from multiple recommenders (indexed by $r$), stacking performs:\n",
    "$$\n",
    "s_i = f(s_{0i}, s_{1i}, \\ldots, s_{ni})\n",
    "$$\n",
    "where $f$ is typically trained by some regression model, e.g. linear regression:\n",
    "$$\n",
    "s_i = \\sum_r \\alpha_r s_{ri}\n",
    "$$\n",
    "\n",
    "In order that the scores be sensibly combined, they must be \"similar enough\", under the combination. This is similarity is not only in score magnitudes (which would be trivially addressed by the weights) but also about score variabilities: if the combination is \"more sensitive\" to one weight of the combination than another, then they are not being combined democratically -- score perturbations of the \"more sensitive\" system would \"weigh more\". For instance, if the scores of two recs systems are combined by a linear regression, then an increment $s \\to s + \\Delta$ in any weight from the first system _should_ have the same effect (up to the coefficients $\\alpha_r$ of the regression) as the same increment on a weight from the second system.\n",
    "\n",
    "This similarity requirement suggests that stacking hybridisations occur as part of, or downstream of, the scoring subsystem of the hybrid recommender. The same scoring function is assigned to the candidates of each recommender, and these scores-per-candidate can be stacked to obtain the output score of the hybrid recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching\n",
    "\n",
    "Suppose you had three doctors: an oncologist, an ophthalmologist, and a parasitologist. A Switching Recommender would take the ophthalmologist's advice on eye-related issues, the oncologist's advice on cancer-related issues, and the parasitologist's advice on parasite-related issues.\n",
    "\n",
    "You might want to use collaborative filtering for users where you have the data, and switch to a knowledge-based system for users where you don't. Or use different recs scores for different target audiences, e.g. recommend products driving conversions for new visitors and driving engagement/loyalty metrics for returning visitors.\n",
    "\n",
    "You might also know that some recommenders perform better than others in different parts of the product catalogue. For example, given that the current PDP is in product category \"makeup >> foundation\" you might want to switch from the generic recommender to a foundation-specific recommender to upsell or improve the visitor's odds of finding the right color. This specific recommender is smaller (and so easier to train) and might benefit from features (e.g. user skin tone) that the generic recommender may not know how to use.\n",
    "\n",
    "If the switching logic is not hard coded but machine-learned with a neural network, then this neural network is known as a _gating network_. Note that gating networks serve a distinct purpose than stacking networks: switching between individual \"experts\" is not the same as blending them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing\n",
    "\n",
    "Mixing shows recommendations from multiple recommenders in a combined display. For instance, Youtube's front page has multiple recommendation carousels. The ranked lists of videos from separate recommenders are shown in separate carousels, but no video is ever shown twice in the combined display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\n",
    "recs = [[\"A\", \"B\", \"C\"], [\"D\", \"E\", \"B\", \"A\"], [\"F\", \"A\", \"G\", \"H\"]]\n",
    "\n",
    "carousel_lenghts = [3, 2, 3]  # lengths of the carousels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Augmentation\n",
    "\n",
    "Augmenting the features (by value imputation), or augmenting the feature space with new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid-recs",
   "language": "python",
   "name": "hybrid-recs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
